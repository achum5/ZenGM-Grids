“Make URL + File uploads work on Vercel”

Goal: Fix uploads on the deployed Vercel site so they behave exactly like Replit preview.

/api/fetch-league must work for:

GET ?url=… — normalize Dropbox/GitHub/GDrive links and stream bytes.

POST — accept local file uploads (JSON or .gz) and stream the raw bytes back.

Must work on Vercel (Node runtime, no 4MB cap, streaming).

Detect gzip by magic bytes and expose X-Content-Encoding: gzip so the client can handle it.

Keep the client flow the same (we fetch our own proxy and parse bytes in the browser).

Implement one of the two versions below based on our Next.js setup. If the repo uses App Router, create app/api/fetch-league/route.ts. If it uses Pages Router, create pages/api/fetch-league.ts. Do not create both.

A) App Router (app/api/fetch-league/route.ts)
export const runtime = "nodejs";        // Full Node, not Edge
export const dynamic = "force-dynamic";

const UA =
  "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36";

function normalizeLeagueUrl(input: string): string {
  const u = new URL(input.trim());

  // Dropbox share -> direct
  if (u.hostname.endsWith("dropbox.com")) {
    u.hostname = "dl.dropboxusercontent.com";
    u.searchParams.set("dl", "1");
    u.searchParams.delete("st");
  }
  if (u.hostname === "dl.dropboxusercontent.com") {
    u.searchParams.delete("st");
  }

  // GitHub blob -> raw
  if (u.hostname === "github.com") {
    const parts = u.pathname.split("/").filter(Boolean);
    if (parts[2] === "blob" && parts.length >= 5) {
      const [user, repo, _blob, branch, ...rest] = parts;
      u.hostname = "raw.githubusercontent.com";
      u.pathname = `/${user}/${repo}/${branch}/${rest.join("/")}`;
      u.search = "";
    }
  }

  // Gist -> raw
  if (u.hostname === "gist.github.com") {
    const parts = u.pathname.split("/").filter(Boolean);
    if (parts.length >= 2) {
      const [user, hash] = parts;
      u.hostname = "gist.githubusercontent.com";
      u.pathname = `/${user}/${hash}/raw`;
      u.search = "";
    }
  }

  // Google Drive file -> direct
  if (u.hostname === "drive.google.com" && u.pathname.startsWith("/file/")) {
    const id = u.pathname.split("/")[3];
    u.pathname = "/uc";
    u.search = "";
    u.searchParams.set("export", "download");
    u.searchParams.set("id", id);
  }

  if (!/^https?:$/.test(u.protocol)) throw new Error("Only http(s) URLs are allowed.");
  return u.toString();
}

function sniffIsGzip(bytes: Uint8Array) {
  return bytes.length >= 2 && bytes[0] === 0x1f && bytes[1] === 0x8b;
}

export async function GET(req: Request) {
  const { searchParams } = new URL(req.url);
  const url = searchParams.get("url");
  if (!url) return new Response(JSON.stringify({ error: "Missing ?url=" }), { status: 400 });

  try {
    const normalized = normalizeLeagueUrl(url);
    const remote = await fetch(normalized, {
      redirect: "follow",
      headers: { "User-Agent": UA, Accept: "*/*", "Accept-Encoding": "identity" },
    });

    if (!remote.ok || !remote.body) {
      return new Response(
        JSON.stringify({ error: `Fetch failed: remote ${remote.status} ${remote.statusText}` }),
        { status: remote.status || 502, headers: { "Content-Type": "application/json" } }
      );
    }

    const headers = new Headers();
    headers.set("Content-Type", remote.headers.get("content-type") || "application/octet-stream");
    const ce = remote.headers.get("content-encoding");
    if (ce) headers.set("X-Content-Encoding", ce);
    headers.set("Cache-Control", "no-store");

    return new Response(remote.body, { headers });
  } catch (e: any) {
    return new Response(JSON.stringify({ error: String(e?.message || e) }), {
      status: 400,
      headers: { "Content-Type": "application/json" },
    });
  }
}

export async function POST(req: Request) {
  try {
    const ct = req.headers.get("content-type") || "";
    let bytes: Uint8Array;

    if (ct.includes("multipart/form-data")) {
      const form = await req.formData();
      const file = form.get("file");
      if (!(file instanceof File)) {
        return new Response(JSON.stringify({ error: "No 'file' field in form data" }), {
          status: 400,
          headers: { "Content-Type": "application/json" },
        });
      }
      bytes = new Uint8Array(await file.arrayBuffer());
    } else {
      // Support raw octet-stream POST as well
      bytes = new Uint8Array(await req.arrayBuffer());
    }

    const headers = new Headers();
    headers.set("Content-Type", "application/octet-stream");
    if (sniffIsGzip(bytes)) headers.set("X-Content-Encoding", "gzip");
    headers.set("Cache-Control", "no-store");

    return new Response(bytes, { headers });
  } catch (e: any) {
    return new Response(JSON.stringify({ error: String(e?.message || e) }), {
      status: 400,
      headers: { "Content-Type": "application/json" },
    });
  }
}

B) Pages Router (pages/api/fetch-league.ts)
import type { NextApiRequest, NextApiResponse } from "next";
import fs from "node:fs";
import fsp from "node:fs/promises";
import path from "node:path";
import formidable from "formidable";

export const config = {
  api: {
    responseLimit: false,   // we stream/pipe or send buffers > 4MB
    bodyParser: false,      // we use formidable for multipart & raw
    externalResolver: true,
  },
};

const UA =
  "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36";

function normalizeLeagueUrl(input: string): string {
  const u = new URL(input.trim());

  if (u.hostname.endsWith("dropbox.com")) {
    u.hostname = "dl.dropboxusercontent.com";
    u.searchParams.set("dl", "1");
    u.searchParams.delete("st");
  }
  if (u.hostname === "dl.dropboxusercontent.com") u.searchParams.delete("st");

  if (u.hostname === "github.com") {
    const parts = u.pathname.split("/").filter(Boolean);
    if (parts[2] === "blob" && parts.length >= 5) {
      const [user, repo, _blob, branch, ...rest] = parts;
      u.hostname = "raw.githubusercontent.com";
      u.pathname = `/${user}/${repo}/${branch}/${rest.join("/")}`;
      u.search = "";
    }
  }

  if (u.hostname === "gist.github.com") {
    const parts = u.pathname.split("/").filter(Boolean);
    if (parts.length >= 2) {
      const [user, hash] = parts;
      u.hostname = "gist.githubusercontent.com";
      u.pathname = `/${user}/${hash}/raw`;
      u.search = "";
    }
  }

  if (u.hostname === "drive.google.com" && u.pathname.startsWith("/file/")) {
    const id = u.pathname.split("/")[3];
    u.pathname = "/uc";
    u.search = "";
    u.searchParams.set("export", "download");
    u.searchParams.set("id", id);
  }

  if (!/^https?:$/.test(u.protocol)) throw new Error("Only http(s) URLs are allowed.");
  return u.toString();
}

function sniffIsGzip(buf: Uint8Array) {
  return buf.length >= 2 && buf[0] === 0x1f && buf[1] === 0x8b;
}

async function parseMultipart(req: NextApiRequest): Promise<Uint8Array> {
  const form = formidable({ multiples: false, keepExtensions: true });
  const { files } = await new Promise<any>((resolve, reject) => {
    form.parse(req, (err, fields, files) => (err ? reject(err) : resolve({ fields, files })));
  });

  const fileObj = files.file || files.upload || Object.values(files)[0];
  if (!fileObj) throw new Error("No file provided");

  // formidable v3+ may return an array
  const f = Array.isArray(fileObj) ? fileObj[0] : fileObj;
  const filepath = f.filepath || f.path;

  const data = await fsp.readFile(filepath);
  // Clean up temp file just in case
  fsp.unlink(filepath).catch(() => {});
  return new Uint8Array(data);
}

export default async function handler(req: NextApiRequest, res: NextApiResponse) {
  try {
    if (req.method === "GET") {
      const urlParam = typeof req.query.url === "string" ? req.query.url : "";
      if (!urlParam) return res.status(400).json({ error: "Missing ?url=" });

      const normalized = normalizeLeagueUrl(urlParam);
      const remote = await fetch(normalized, {
        redirect: "follow",
        headers: { "User-Agent": UA, Accept: "*/*", "Accept-Encoding": "identity" },
      });

      if (!remote.ok || !remote.body) {
        return res
          .status(remote.status || 502)
          .json({ error: `Fetch failed: remote ${remote.status} ${remote.statusText}` });
      }

      res.setHeader("Content-Type", remote.headers.get("content-type") || "application/octet-stream");
      const ce = remote.headers.get("content-encoding");
      if (ce) res.setHeader("X-Content-Encoding", ce);
      res.setHeader("Cache-Control", "no-store");

      // @ts-ignore Node stream piping
      remote.body.pipe(res);
      return;
    }

    if (req.method === "POST") {
      const ct = req.headers["content-type"] || "";
      let bytes: Uint8Array;

      if (typeof ct === "string" && ct.includes("multipart/form-data")) {
        bytes = await parseMultipart(req);
      } else {
        // raw octet-stream
        const chunks: Buffer[] = [];
        await new Promise<void>((resolve, reject) => {
          req.on("data", (c) => chunks.push(c));
          req.on("end", () => resolve());
          req.on("error", reject);
        });
        bytes = new Uint8Array(Buffer.concat(chunks));
      }

      res.setHeader("Content-Type", "application/octet-stream");
      if (sniffIsGzip(bytes)) res.setHeader("X-Content-Encoding", "gzip");
      res.setHeader("Cache-Control", "no-store");
      res.status(200).send(Buffer.from(bytes));
      return;
    }

    res.setHeader("Allow", "GET, POST");
    res.status(405).end("Method Not Allowed");
  } catch (err: any) {
    res.status(400).json({ error: String(err?.message || err) });
  }
}

C) Vercel function config (avoid slow-download timeouts)

Create or update vercel.json:

{
  "functions": {
    "api/fetch-league.ts": { "maxDuration": 60 }
  }
}


(If using App Router, Vercel infers the function path; the duration hint still helps.)

D) Frontend: unified upload code (works on Vercel + Replit)

URL upload (unchanged):

const r = await fetch(`/api/fetch-league?url=${encodeURIComponent(inputUrl)}`);
if (!r.ok) throw new Error(await r.text());
const data = new Uint8Array(await r.arrayBuffer());
const encoding = r.headers.get("x-content-encoding"); // "gzip" or null
// parse bytes accordingly


File upload (local .json or .gz) — send via multipart to the same endpoint:

const fd = new FormData();
fd.append("file", file); // from <input type="file">
const r = await fetch("/api/fetch-league", { method: "POST", body: fd });
if (!r.ok) throw new Error(await r.text());
const data = new Uint8Array(await r.arrayBuffer());
const encoding = r.headers.get("x-content-encoding"); // "gzip" if gz
// parse bytes accordingly


Do not attempt to decode gzip on the server. Keep server as a dumb streaming proxy so Vercel limits aren’t hit. The client already knows how to handle JSON vs gzip using encoding or magic-byte sniffing.

E) Acceptance tests (run on the Vercel domain)

URL GET: Dropbox share, direct Dropbox, GitHub blob/raw, Google Drive file — all should load without 4MB errors and surface remote <status> if blocked.

File POST: Upload a large .json and a .gz league file via the file picker. Both must parse on the client. Verify X-Content-Encoding: gzip header is present for .gz.

Pass criteria: All uploads (URL and local) work on Vercel exactly as they do in Replit preview. Errors show clear messages including remote status codes.

Use that verbatim. It tells Replit exactly what to build and where, with working code for both router styles and with file uploads handled for .json and .gz.