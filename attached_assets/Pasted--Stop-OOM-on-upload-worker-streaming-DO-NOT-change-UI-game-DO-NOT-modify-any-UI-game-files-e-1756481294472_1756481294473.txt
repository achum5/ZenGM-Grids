“Stop OOM on upload (worker + streaming). DO NOT change UI/game.”

DO NOT modify any UI/game files except the upload handlers.
Only add the files below and wire them in.

0) Ensure dependency
npm i fflate

1) Add streaming parser worker (runs off the main thread)

Create: client/src/workers/leagueParse.worker.ts

// Runs in a Web Worker. Streaming gunzip + decode to a single string (no giant byte buffer)
// Then JSON.parse and post back. Avoids main-thread memory spikes.

import { AsyncGunzip } from "fflate";

type MsgIn = { buffer: ArrayBuffer; hinted?: "gzip" | null };
type MsgOut =
  | { ok: true; league: any }
  | { ok: false; error: string };

const td = new TextDecoder();

function isGzip(u8: Uint8Array) {
  return u8.length >= 2 && u8[0] === 0x1f && u8[1] === 0x8b;
}

self.onmessage = async (e: MessageEvent<MsgIn>) => {
  try {
    let u8 = new Uint8Array(e.data.buffer); // transferred from main
    const hinted = e.data.hinted;

    // If not gzip, decode directly
    if (!(hinted === "gzip" || isGzip(u8))) {
      const text = td.decode(u8);
      const league = JSON.parse(text);
      (self as any).postMessage({ ok: true, league } as MsgOut);
      return;
    }

    // Stream gunzip to avoid allocating one giant decompressed buffer
    const gunzip = new AsyncGunzip();
    const chunks: string[] = [];

    gunzip.ondata = (chunk, final) => {
      chunks.push(td.decode(chunk, { stream: !final }));
      if (final) {
        try {
          const text = chunks.join("");
          const league = JSON.parse(text);

          // Optional thinning to save RAM; uncomment only if you still hit OOM
          // if (league?.gameAttributes) {
          //   delete league.gameAttributes.events;
          //   delete league.gameAttributes.boxScores;
          //   delete league.gameAttributes.schedule;
          // }

          (self as any).postMessage({ ok: true, league } as MsgOut);
        } catch (err: any) {
          (self as any).postMessage({ ok: false, error: String(err?.message || err) } as MsgOut);
        }
      }
    };

    gunzip.onerr = (msg, code) => {
      (self as any).postMessage({ ok: false, error: `${msg} (${code})` } as MsgOut);
    };

    // Feed compressed data; true = final chunk
    gunzip.push(u8, true);
  } catch (err: any) {
    (self as any).postMessage({ ok: false, error: String(err?.message || err) } as MsgOut);
  }
};

2) Add a small helper to use the worker

Create/overwrite: client/src/lib/leagueIO.ts

import { gunzipSync } from "fflate";

// NOTE: keep these two fetch/read helpers from earlier:

export async function fetchLeagueBytesViaVercel(rawUrl: string) {
  const r = await fetch(`/api/fetch-league?url=${encodeURIComponent(rawUrl)}`);
  if (!r.ok) {
    const t = await r.text().catch(() => "");
    throw new Error(`URL fetch failed (${r.status}): ${t || r.statusText}`);
  }
  const hinted = r.headers.get("x-content-encoding") as ("gzip" | null);
  const bytes = new Uint8Array(await r.arrayBuffer());
  return { bytes, hinted };
}

export async function fileToBytes(file: File) {
  const bytes = new Uint8Array(await file.arrayBuffer());
  const hinted = file.name.toLowerCase().endsWith(".gz") ? ("gzip" as const) : null;
  return { bytes, hinted };
}

// FAST path for small files (still available if you want it)
export function parseLeague(bytes: Uint8Array, hinted?: "gzip" | null) {
  const gz = hinted === "gzip" || (bytes[0] === 0x1f && bytes[1] === 0x8b);
  const raw = gz ? gunzipSync(bytes) : bytes;
  const text = new TextDecoder().decode(raw);
  return JSON.parse(text);
}

// SAFE path for big files: off-main-thread + streaming gunzip (prevents OOM)
export function parseLeagueInWorker(bytes: Uint8Array, hinted?: "gzip" | null): Promise<any> {
  return new Promise((resolve, reject) => {
    const worker = new Worker(new URL("../workers/leagueParse.worker.ts", import.meta.url), {
      type: "module",
    });
    worker.onmessage = (ev: MessageEvent<{ ok: boolean; league?: any; error?: string }>) => {
      if (ev.data.ok) resolve(ev.data.league);
      else reject(new Error(ev.data.error || "Worker parse failed"));
      worker.terminate();
    };
    worker.onerror = (e) => {
      reject(new Error(e.message || "Worker error"));
      worker.terminate();
    };

    // Transfer the underlying buffer to avoid copying
    worker.postMessage({ buffer: bytes.buffer, hinted: hinted ?? null }, [bytes.buffer]);
  });
}

3) Update ONLY the upload handlers to use the worker

(Do not change any other UI/game code.)

In your upload component:

import {
  fetchLeagueBytesViaVercel,
  fileToBytes,
  parseLeagueInWorker, // use worker for big files
} from "@/lib/leagueIO";
import { setLeagueInMemory } from "@/lib/leagueMemory"; // from earlier step to avoid storage quota

// URL handler
async function onUrlSubmit(url: string) {
  setLoading(true);
  try {
    const { bytes, hinted } = await fetchLeagueBytesViaVercel(url);
    const league = await parseLeagueInWorker(bytes, hinted); // <-- worker
    setLeagueInMemory(league);
    // call your existing game/UI function here (unchanged)
  } catch (e: any) {
    console.error(e);
    toast?.error?.(e.message || "Failed to load URL");
  } finally {
    setLoading(false);
  }
}

// File handler
async function onFileChosen(file: File) {
  setLoading(true);
  try {
    const { bytes, hinted } = await fileToBytes(file);
    const league = await parseLeagueInWorker(bytes, hinted); // <-- worker
    setLeagueInMemory(league);
    // call your existing game/UI function here (unchanged)
  } catch (e: any) {
    console.error(e);
    toast?.error?.(e.message || "Failed to load file");
  } finally {
    setLoading(false);
  }
}


And make sure the file input accepts gzip:

<input type="file" accept=".json,.gz,application/gzip,application/x-gzip" />

Why this fixes “Aw, Snap”

No sync gunzip on the main thread. We stream gunzip chunks inside a worker.

No giant decompressed byte buffer. We decode chunks directly to text, then one JSON string, then parse.

No localStorage/sessionStorage writes. Keep data in memory (as you already switched to) to avoid quota crashes.

This stays strictly in the upload layer—zero changes to gameplay or UI. If you still hit OOM with extremely huge leagues, uncomment the tiny “thinning” block in the worker to drop known heavy fields before posting back.