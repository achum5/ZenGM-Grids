‚ÄúImplement BBGM-style league upload (URL + file, json + gz) that works on Vercel‚Äù

High-level rules (do this first)

All heavy work happens in the browser (like BBGM):

read file/URL ‚Üí (if gz) gunzip ‚Üí JSON.parse ‚Üí use in UI.

Do not POST the whole league to any server endpoint.

We only need one server thing: a tiny URL proxy at /api/fetch-league so links (Dropbox/GitHub/Drive/Gist) load on Vercel without CORS issues.

Offload parsing to a Web Worker so the main UI never freezes or crashes.

No size/time limits hit on Vercel because the function only streams bytes, never parses or holds big memory.

Keep the current UI, routes, and player search unchanged. Only swap the data-loading layer.

0) Dependencies
npm i fflate

1) Serverless URL proxy for Vercel

Create api/fetch-league.ts at the repo root:

import type { VercelRequest, VercelResponse } from "@vercel/node";
import { Readable } from "node:stream";

export const config = { maxDuration: 60 };

const UA =
  "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36";

function normalize(input: string) {
  const u = new URL(input.trim());

  // Dropbox ‚Üí direct (keep tokens, force dl=1)
  if (
    u.hostname === "www.dropbox.com" ||
    u.hostname === "dropbox.com" ||
    u.hostname === "dl.dropbox.com" ||
    u.hostname.endsWith("dropbox.com")
  ) {
    u.hostname = "dl.dropboxusercontent.com";
    u.searchParams.set("dl", "1");
  }

  // GitHub "blob" ‚Üí raw
  if (u.hostname === "github.com") {
    const p = u.pathname.split("/").filter(Boolean);
    if (p.length >= 5 && p[2] === "blob") {
      const [user, repo, _blob, branch, ...rest] = p;
      u.hostname = "raw.githubusercontent.com";
      u.pathname = `/${user}/${repo}/${branch}/${rest.join("/")}`;
      u.search = "";
    }
  }

  // Gist page ‚Üí raw
  if (u.hostname === "gist.github.com") {
    const p = u.pathname.split("/").filter(Boolean);
    if (p.length >= 2) {
      const [user, hash] = p;
      u.hostname = "gist.githubusercontent.com";
      u.pathname = `/${user}/${hash}/raw`;
      u.search = "";
    }
  }

  // Google Drive file ‚Üí direct
  if (u.hostname === "drive.google.com" && u.pathname.startsWith("/file/")) {
    const id = u.pathname.split("/")[3];
    u.pathname = "/uc";
    u.search = "";
    u.searchParams.set("export", "download");
    u.searchParams.set("id", id);
  }

  if (!/^https?:$/.test(u.protocol)) throw new Error("Only http(s) URLs are allowed.");
  return u.toString();
}

export default async function handler(req: VercelRequest, res: VercelResponse) {
  try {
    const url = typeof req.query.url === "string" ? req.query.url : "";
    if (!url) return res.status(400).json({ error: "Missing ?url=" });

    const normalized = normalize(url);
    const looksGzipByExt = /\.json\.gz$|\.gz$/i.test(new URL(normalized).pathname);

    const upstream = await fetch(normalized, {
      redirect: "follow",
      headers: { "User-Agent": UA, Accept: "*/*", "Accept-Encoding": "identity" }, // don't double-compress
    });

    if (!upstream.ok || !upstream.body) {
      return res
        .status(upstream.status || 502)
        .json({ error: `Fetch failed: remote ${upstream.status} ${upstream.statusText}` });
    }

    const ct = upstream.headers.get("content-type") || "application/octet-stream";
    res.setHeader("Content-Type", ct);

    // Hint to client if this is really gzip even when servers don't set Content-Encoding
    const ce = upstream.headers.get("content-encoding");
    const isGzipType = /\b(gzip|x-gzip)\b/i.test(ct) || /application\/(gzip|x-gzip)/i.test(ct);
    if (ce) res.setHeader("X-Content-Encoding", ce);
    else if (looksGzipByExt || isGzipType) res.setHeader("X-Content-Encoding", "gzip");

    res.setHeader("Cache-Control", "no-store");

    Readable.fromWeb(upstream.body as any).pipe(res);
  } catch (e: any) {
    res.status(400).json({ error: String(e?.message || e) });
  }
}


Create vercel.json:

{
  "functions": {
    "api/**": { "maxDuration": 60 }
  }
}


Optional (dev/preview): If your Replit preview needs the same path, add a tiny Express route /api/fetch-league that does the same streaming proxy. (But if preview already works, skip.)

2) Client helpers (download, sniff gzip, parse)

Create client/src/lib/leagueIO.ts:

import { gunzipSync } from "fflate";

export async function fetchLeagueBytes(url: string) {
  const r = await fetch(`/api/fetch-league?url=${encodeURIComponent(url)}`);
  if (!r.ok) {
    const text = await r.text().catch(() => "");
    throw new Error(`URL fetch failed (${r.status}): ${text || r.statusText}`);
  }
  const hinted = r.headers.get("x-content-encoding") as ("gzip" | null);
  const bytes = new Uint8Array(await r.arrayBuffer());
  return { bytes, hinted };
}

export async function fileToBytes(file: File) {
  const bytes = new Uint8Array(await file.arrayBuffer());
  const hinted = file.name.toLowerCase().endsWith(".gz") ? ("gzip" as const) : null;
  return { bytes, hinted };
}

// Small/medium sync fallback
export function parseLeagueSync(bytes: Uint8Array, hinted?: "gzip" | null) {
  const needGzip = hinted === "gzip" || (bytes[0] === 0x1f && bytes[1] === 0x8b);
  const raw = needGzip ? gunzipSync(bytes) : bytes;
  const text = new TextDecoder().decode(raw);
  return JSON.parse(text);
}


Create Web Worker to offload big parses: client/src/workers/leagueParse.worker.ts:

import { gunzip } from "fflate";
const isGzip = (u8: Uint8Array) => u8.length >= 2 && u8[0] === 0x1f && u8[1] === 0x8b;

self.onmessage = async (e: MessageEvent) => {
  try {
    const { bytes, hinted } = e.data as { bytes: ArrayBuffer; hinted?: "gzip" | null };
    let u8 = new Uint8Array(bytes); // transferred, zero-copy

    if (hinted === "gzip" || isGzip(u8)) {
      u8 = await new Promise<Uint8Array>((resolve, reject) => {
        gunzip(u8, (err, out) => (err ? reject(err) : resolve(out)));
      });
    }

    const text = new TextDecoder().decode(u8);
    const league = JSON.parse(text);
    (self as any).postMessage({ ok: true, league });
  } catch (err: any) {
    (self as any).postMessage({ ok: false, error: String(err?.message || err) });
  }
};


Add a helper to use the worker (append to leagueIO.ts):

export async function parseLeagueInWorker(bytes: Uint8Array, hinted: "gzip" | null) {
  // Transfer buffer to avoid duplication
  const ab = bytes.buffer.slice(bytes.byteOffset, bytes.byteOffset + bytes.byteLength);
  const worker = new Worker(new URL("../workers/leagueParse.worker.ts", import.meta.url), { type: "module" });

  return new Promise<any>((resolve, reject) => {
    const cleanup = () => worker.terminate();
    worker.onmessage = (e) => {
      cleanup();
      const { ok, league, error } = e.data || {};
      ok ? resolve(league) : reject(new Error(error || "Parse failed"));
    };
    worker.onerror = (ev) => {
      cleanup();
      reject(new Error(ev.message || "Worker error"));
    };
    worker.postMessage({ bytes: ab, hinted }, [ab as any]);
  });
}

3) Wire it into the existing upload UI without changing your UI/game logic

In your current upload component (the one you had in the good version), replace only the data-loading part.

import { fetchLeagueBytes, fileToBytes, parseLeagueInWorker, parseLeagueSync } from "@/lib/leagueIO";

async function onUrlSubmit(inputUrl: string) {
  setLoading(true);
  try {
    const { bytes, hinted } = await fetchLeagueBytes(inputUrl);
    // Use worker parse for big files (safe for all sizes)
    const league = await parseLeagueInWorker(bytes, hinted);

    // üî¥ DO NOT POST league to /api/*
    // ‚úÖ Instead, feed league into your existing UI/game pipeline exactly as before:
    // e.g. startGame(league) or setLeagueState(league) or navigate with state, etc.
  } catch (e: any) {
    toast.error(e.message || "Failed to load URL");
  } finally {
    setLoading(false);
  }
}

async function onFileChosen(file: File) {
  setLoading(true);
  try {
    const { bytes, hinted } = await fileToBytes(file);
    const league = await parseLeagueInWorker(bytes, hinted);
    // same: use league directly in client
  } catch (e: any) {
    toast.error(e.message || "Failed to load file");
  } finally {
    setLoading(false);
  }
}


Make sure the file input accepts GZip:

<input type="file" accept=".json,.gz,application/gzip,application/x-gzip" />

4) (Optional) Preview parity

If your Replit preview needs the same proxy path, add a dev route in your Express/Vite dev server:
GET /api/fetch-league that does the same streaming passthrough. Otherwise, skip.

5) Build/Deploy settings (Vercel)

Framework: Vite

Build command: npm run build

Output directory: dist/public

No Next.js.

Keep the vercel.json above.

6) Error handling & edge cases (make it bulletproof)

When /api/fetch-league fails, read .text() and show that string in the toast so users see Dropbox/GitHub permission problems.

Detect ‚ÄúHTML‚Äù by content-type or if response starts with < ‚Äî throw a clean error (‚ÄúThis link returns a web page, not a file‚Äù).

Some Dropbox st= tokens expire; normalization keeps tokens but always set dl=1.

Google Drive file must be public or shared ‚Äúanyone with link‚Äù; otherwise you‚Äôll get an HTML auth page ‚Äî surface that to the user.

Mobile Safari can be memory-tight; the Worker approach avoids main-thread freezes.

Don‚Äôt keep references to the raw Uint8Array after parsing; let it GC.

7) Quick QA checklist

https://<your-site>.vercel.app/api/fetch-league?url=<dropbox.gz> streams bytes (not an HTML page).

In the app:

Upload local .json ‚Üí loads.

Upload local .gz ‚Üí loads.

Paste URL .json ‚Üí loads.

Paste URL .gz ‚Üí loads.

DevTools ‚Üí Network: no calls to /api/process-league, /api/generate-grid, etc.

UI remains exactly as before (player search, gameplay).